<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.6" />


<title>Predict Breast Cancer using TensorFlow - Andrea Perlato</title>
<meta property="og:title" content="Predict Breast Cancer using TensorFlow - Andrea Perlato">



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/graphpost/">Graph</a></li>
    
    <li><a href="/mlpost/">Machine Learning</a></li>
    
    <li><a href="/aipost/">Artificial Intelligence</a></li>
    
    <li><a href="/tspost/">Time Series</a></li>
    
    <li><a href="/theorypost/">Theory</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Predict Breast Cancer using TensorFlow</h1>

    

    <div class="article-content">
      


<style>
body {
text-align: justify}
</style>
<p>In this article we try to predict if a patient’s diagnosis of breast tissue is malignant or bening. From the code below, using the <strong>feature_names</strong> function we can explore the name of all the predictors involved in the breast cancer such as for example: mean radius, mean perimeter and so forth. Moreover, using the funtion <strong>target_names</strong> we have the two level of the response variable (malignant, benign).
To have a better understanding of the dataset here the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"><strong>link</strong></a>.</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import tensorflow as tf

from sklearn.datasets import load_breast_cancer 
data = load_breast_cancer()
list(data.feature_names) # predictors</code></pre>
<pre><code>## [&#39;mean radius&#39;, &#39;mean texture&#39;, &#39;mean perimeter&#39;, &#39;mean area&#39;, &#39;mean smoothness&#39;, &#39;mean compactness&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;, &#39;mean symmetry&#39;, &#39;mean fractal dimension&#39;, &#39;radius error&#39;, &#39;texture error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;, &#39;smoothness error&#39;, &#39;compactness error&#39;, &#39;concavity error&#39;, &#39;concave points error&#39;, &#39;symmetry error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst smoothness&#39;, &#39;worst compactness&#39;, &#39;worst concavity&#39;, &#39;worst concave points&#39;, &#39;worst symmetry&#39;, &#39;worst fractal dimension&#39;]</code></pre>
<pre class="python"><code>list(data.target_names) # response variable</code></pre>
<pre><code>## [&#39;malignant&#39;, &#39;benign&#39;]</code></pre>
<p>Now, we can use the function <strong>train_test_split</strong> from <strong>sklearn</strong> and calling this function we can split the model with a test set of 30% of the original data set.</p>
<pre class="python"><code># Select how the model wwill perform in the future
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3)
N, D = X_train.shape # number of observation and variables

# Scale the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)</code></pre>
<p>In the code above, we also scaled the data, the basic idea is that because the output is a linear combination of the input we don’t want to have one or more input with a very large range and other inputs with a very small range. If this happens, then the weights will be too sensitive when the input has large range and not sensitive when input has small range. We can do that using the <a href="https://en.wikipedia.org/wiki/Standard_score"><strong>z points</strong></a>. In python we can transform the data in z points using the <strong>StandarScaler</strong> function used above.</p>
<p>Now, we can use TensorFlow, and first we have to build a model object which is an object of type sequential. This takes it in a list of two objects called <strong>input</strong> and <strong>dense</strong>. </br>
The <strong>input</strong> jusy specify the size of the input and is called <strong>D</strong> (see the code above X_train_shape). </br>
The <strong>dense</strong> layer is instead where the real work happens: it takes the input and does a linear transformation to get an output of size 1. The linear transformation we want to apply is the <a href="https://www.andreaperlato.com/aipost/the-activation-function/"><strong>sigmoid activation function</strong></a> so that in output we are in a range of 0 and 1.</p>
<pre class="python"><code># Build the model in TensorFlow
model = tf.keras.models.Sequential([
  tf.keras.layers.Input(shape=(D,)),
  tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;) # use sigmoid function for every epochs
])

model.compile(optimizer=&#39;adam&#39;, # use adaptive momentum
              loss=&#39;binary_crossentropy&#39;,
              metrics=[&#39;accuracy&#39;])
              
# Train the Model
r = model.fit(X_train, y_train, validation_data=(X_test, y_test))

# Evaluate the model</code></pre>
<pre><code>## Train on 398 samples, validate on 171 samples
## 
##  32/398 [=&gt;............................] - ETA: 5s - loss: 0.7772 - accuracy: 0.6562
## 398/398 [==============================] - 1s 1ms/sample - loss: 0.6014 - accuracy: 0.7261 - val_loss: 0.5976 - val_accuracy: 0.6667</code></pre>
<pre class="python"><code>print(&quot;Train score:&quot;, model.evaluate(X_train, y_train)) # evaluate returns loss and accuracy</code></pre>
<pre><code>## 
## 398/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 30us/sample - loss: 0.5403 - accuracy: 0.7563
## Train score: [0.5699630466537859, 0.75628144]</code></pre>
<pre class="python"><code>print(&quot;Test score:&quot;, model.evaluate(X_test, y_test)) # evaluate returns loss and accuracy</code></pre>
<pre><code>## 
## 171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 36us/sample - loss: 0.6113 - accuracy: 0.6667
## Test score: [0.5975685590191891, 0.6666667]</code></pre>
<p>From the code above we used the <a href="https://www.andreaperlato.com/aipost/adaptive-momentum/"><strong>AdaM adaptive momentum</strong></a> as optimizer for the gradient descent using <a href="https://www.andreaperlato.com/aipost/mini-batch-gradient-descent/"><strong>mini-batch</strong></a>. We apply the sigmoid function for every epochs.
The results say that we have 56% of accuracy on both trin and test set. </br>
We can also plot the <strong>loss per iteration</strong> using the code below.</p>
<pre class="python"><code>import matplotlib.pyplot as plt
# plt.plot(r.history[&#39;loss&#39;], label=&#39;loss&#39;)
# plt.plot(r.history[&#39;val_loss&#39;], label=&#39;val_loss&#39;)
# plt.legend()
# plt.show()</code></pre>
<center>
<img src="/img/cancerloss.png" style="width:40.0%" />
</center>
<p>The graph above shows the <strong>loss per iteration</strong>. From the code above we can see that the <strong>training loss</strong> is stored in a key called <strong>loss</strong>, while the <strong>validatin loss</strong> is stored in a key called <strong>val_loss</strong>. From the graph, there is a nice decrease in the last iterationas expected.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://www.rstudio.com/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-51254710-89', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

