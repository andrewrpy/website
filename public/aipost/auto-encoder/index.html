<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.6" />


<title>Auto Encoder - Andrea Perlato</title>
<meta property="og:title" content="Auto Encoder - Andrea Perlato">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/graphpost/">Graph</a></li>
    
    <li><a href="/mlpost/">Machine Learning</a></li>
    
    <li><a href="/aipost/">Artificial Intelligence</a></li>
    
    <li><a href="/tspost/">Time Series</a></li>
    
    <li><a href="/theorypost/">Theory</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Auto Encoder</h1>

    

    <div class="article-content">
      


<style>
body {
text-align: justify}
</style>
<p>It encodes itself using <strong>Visible Input Nodes</strong>, and the <strong>Visible Output Nodes</strong> are decoded using <strong>Hidden Nodes</strong>, in order to be identical to the Input Nodes. </br>
It is not a pure <strong>Unsupervised Deep Learning</strong> algorithm, but it is a <strong>Self-Supervised Deep Learning</strong> algorithm.</p>
<center>
<img src="/img/aenodesbmp.png" style="width:30.0%" />
</center>
<p>Auto Encoders can be used for <strong>Feature Detection</strong>. Once we have encoded our data, the Hidden Nodes also called <strong>Encoder Nodes</strong>, will be represent certain features which are important in ur data. For example, these features, founded via Auto Encoder, can be used to build a powerful Recommender System.</p>
<p>From the figure below, we are using an auto encoder for movies. These are movies that person have watched and rated. </br>
First, we have to train the Auto Encode, and from the figure above, we have to reduce four values (from movie 1 to movie 4) in a smaller space of the Hidden Layer (also known as Encoder Layer).</p>
<center>
<img src="/img/aebwbmp.png" style="width:50.0%" />
</center>
<p>We colored the connections in <strong>blue=multiplication by 1</strong> and <strong>black=multiplication by -1</strong>. </br>
In reality the <a href="https://www.andreaperlato.com/aipost/the-activation-function/"><strong>Hyperbolic Activation Tangent Function</strong></a> is usually used in Auto Encoders. </br></p>
<p>In the figure above, we have in input <strong>Movie1=1</strong> and the <strong>Other Movies=0</strong>. In this case the <strong>Hidden Nodes</strong> are both to <strong>1</strong> because the blue connections are multiplied by 1, and the zeros always just add zero. </br>
Now, having the Hidden Nodes, we can calculate the Output Nodes. The Top Right Output Node is 1+1=<strong>2</strong>, the Second Output Node is 1 -1=<strong>0</strong>. The same is for the Third Output Node. Last Output Node is -1-1=<strong>-2</strong>. </br>
This is a preliminary output, because in the Auto Encoder we also have a <a href="https://www.andreaperlato.com/aipost/cnn-and-softmax/"><strong>Softmax Function</strong></a> on the end. </br>
Basically the Softmax Function takes the highest value, in this case <strong>2</strong>, and it turns that into 1, and everything else into <strong>0</strong>. And as we can see from the figure below, after the Softmax Function, we have in Output the same result that we have in Input.</p>
<center>
<img src="/img/aesoftmax.png" style="width:50.0%" />
</center>
<p>We can encode the Input into a small format where we just have <strong>Two Hidden Values</strong>. There are much more detail in the article: <a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/"><strong>Neural Networks Are Impressively Good At Compression</strong></a>.</p>
<p>Prova.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://www.rstudio.com/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-51254710-89', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

