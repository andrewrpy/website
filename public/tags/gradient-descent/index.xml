<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gradient descent on Andrea Perlato</title>
    <link>/tags/gradient-descent/</link>
    <description>Recent content in gradient descent on Andrea Perlato</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/gradient-descent/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gradient Descent Video Interview</title>
      <link>/theorypost/gradient-descent-video-interview/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/theorypost/gradient-descent-video-interview/</guid>
      <description>body {text-align: justify}.rwd-video {height: 0;overflow: hidden;padding-bottom: 56.25%;padding-top: 30px;position: relative;}.rwd-video iframe,.rwd-video object,.rwd-video embed {height: 100%;left: 0;position: absolute;top: 0;width: 100%;}</description>
    </item>
    
    <item>
      <title>Gradient Checking</title>
      <link>/aipost/gradient-checking/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/gradient-checking/</guid>
      <description>body {text-align: justify}When we implement backpropagation there is a test called Gradient Checking that helps to make sure that the implementation of backpropagation is correct.
Looking at the figure above we can get much better estimate of gradient if we use a larger approximation of the derivative using a double triangle.The hiight of the triagle in the figure can be seen as follow:</description>
    </item>
    
    <item>
      <title>Gradient Descent with Momentum</title>
      <link>/aipost/gradient-descent-with-momentum/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/gradient-descent-with-momentum/</guid>
      <description>body {text-align: justify}Gradient Descent with momentum or just Momentum is an advanced optimization algorithm that speeds up the optimization of the cost function J. It makes use of the moving average to update the trainable parameters of the neural network. Moving average is the average calculated over n successive values rather than the whole set of values. Mathematically, it is denoted as follow:
\[A_{t}=\beta A_{t-1}+(1-\beta) X_{t}\]</description>
    </item>
    
    <item>
      <title>Mini-batch Gradient Descent</title>
      <link>/aipost/mini-batch-gradient-descent/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/mini-batch-gradient-descent/</guid>
      <description>body {text-align: justify}In Batch Gradient Descent on every interation we go through the entire training set.From the figure below we can see the cost function J on the left a batch gradient descent that decrease every single interation. On the right we have the cost function J of a mini-batch gradient descent where in every interatin our processing in training on a different train-set; that is why the loss function J is going to be a little noisier.</description>
    </item>
    
    <item>
      <title>Vanishing Gradient</title>
      <link>/aipost/vanishing-gradient/</link>
      <pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/vanishing-gradient/</guid>
      <description>body {text-align: justify}One of the problems of training a deep neural network is the vanishing and exploding gradient: when we train a deep network the derivatives or the slope can get very big or very small or exponentially small and this makes training difficult. We have to choose very carefully the random weight initialization in order to avoid this problem.
\[\omega^{[l]}=\left[\begin{array}{cc}{1.5} &amp;amp; {0} \\ {0} &amp;amp; {1.</description>
    </item>
    
    <item>
      <title>Gradient Descent Step by Step</title>
      <link>/theorypost/gradient-descent-step-by-step/</link>
      <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/theorypost/gradient-descent-step-by-step/</guid>
      <description>body {text-align: justify}This article is a summary of the StatQuest video made by Josh Starmer. Click here to see the video explained by Josh Starmer. 
Introduction In statistics, Machine Learning and other Data Science fields, we optimize a lot of stuff. For example in linear regresion, we optimize the Intercept and Slope, or when we use Logistic Regression we optimize the squiggle. Moreover, in t-SNE we optimize clusters.</description>
    </item>
    
    <item>
      <title>How Neural Network learn? An example of risk of churn.</title>
      <link>/aipost/how-neural-network-learn/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/aipost/how-neural-network-learn/</guid>
      <description>body {text-align: justify}Having a one layer neural network (single layer feedforeward) with the output value to be compare to the actual value. Baed on the activation function we have our output. In order to be able to lear, we have to compare the output value with the actual value via the cost funtion which is the half of the squred difference output and actual value.</description>
    </item>
    
  </channel>
</rss>