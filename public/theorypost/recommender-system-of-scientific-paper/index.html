<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.6" />


<title>Recommender System of Scientific Paper - Andrea Perlato</title>
<meta property="og:title" content="Recommender System of Scientific Paper - Andrea Perlato">



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/graphpost/">Graph</a></li>
    
    <li><a href="/mlpost/">Machine Learning</a></li>
    
    <li><a href="/aipost/">Artificial Intelligence</a></li>
    
    <li><a href="/tspost/">Time Series</a></li>
    
    <li><a href="/theorypost/">Theory</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Recommender System of Scientific Paper</h1>

    

    <div class="article-content">
      


<style>
body {
text-align: justify}
</style>
<p>Many scientists consider the search for related work as an extremely time-consuming part of their responsibilities. The enormity of time taken is partly caused bythe increasing number of publications, which grows exponentially at a yearly rate of 3.7%. </br>
Instead of entering just keywords, a user may provide entire documents, including reference lists as input and make implicit and explicit ratings to improve recommendations. Instead of solely relying on text mining, recommender system could combines citation analysis, implicit ratings, explicit ratings, author analysis and source analysis to a recommender articles to the users. For more details look at this <a href="https://www.researchgate.net/publication/200610399_Scienstein_A_Research_Paper_Recommender_System"><strong>paper</strong></a>.</p>
<p>Recommender system is designed to predict the user preference and how to recommend the right items in order to create a user personalization experience.
There are two types of recommender system: </br>
1 - Content based filtering: focused on the similarity attributes of the items to give recommendations. </br>
2 - Collaborative filtering: focused on the similarity attribute of the users finding people with similar tastes based on a similarity measure: <strong>memory based</strong> and <strong>model based</strong>.</p>
<center>
<p><img src="/img/recsys.png" style="width:40.0%" /></p>
</center>
<p>From the figure above, the content based filtering is able to find similar items of the favorite items of the user, such as the mouse and the printer based on the keybord and the joystick. The recommendation is based on the similarity.
On the contrary, in the collaborative filtering is focused on the similarity attributes of the users, finding peole with similar traits based on a similarity measure. There are two measures: memory based and model based.</p>
<p>The <strong>memory based recommendation</strong> is looking items liked by similar people in order to create a ranked list of recommendations. We can sort the ranked list to recommend the top n items to the user.
The Person correlation and cosine similarity are used.
Here the Pearson correlation formula:</p>
<p><span class="math display">\[
\operatorname{simil}(x, y)=\frac{\sum_{i \in I_{y}}\left(r_{z, i}-\bar{r}_{z}\right)\left(r_{y, i}-\bar{r}_{y}\right)}{\sqrt{\sum_{i \in I_{y}}\left(r_{z, i}-\bar{r}_{z}\right)^{2}} \sqrt{\sum_{i \in I_{y}, i}}\left(r_{y, i}-\bar{r}_{y}\right)^{2}}
\]</span></p>
<p>and the cosine similarity formula:</p>
<p><span class="math display">\[
\operatorname{simil}(z, y)=\cos (\vec{x}, \vec{y})=\frac{\vec{x} \cdot \vec{y}}{|\vec{x}||\times| \vec{y}||}=\frac{\sum_{i \in I_{y}} r_{z, i} r_{y, i}}{\sqrt{\sum_{i \in l_{z}} r_{z, i}^{2}} \sqrt{\sum_{i \in l_{y}} r_{y, i}^{2}}}
\]</span></p>
<p>The cosine similiarity formula (see on top of this article) makes sure how to separate two terms where each term is represented by a vector and we are interested in the angle between these two vectors. If the cosine similarity is close to 1, both terms are very similar.
In the memory based recommendation the <strong>similarity matrix is used</strong>.</p>
<center>
<p><img src="/img/similaritymatrix.png" style="width:60.0%" /></p>
</center>
<p>From the figure above we can see on the left the <strong>item-item similarity</strong> which is calculated by looking into co-ranked items only. Form example, for the items <strong>i</strong> and <strong>j</strong> the similarity is computed by calculating similarity between rating the i and j columns (items) but only in the cells where we have a rate (blue rectangles). Another approach is to use the <strong>user-item similarity</strong>, on the right of the figure above. This approach is looking into correlated items only in rows (users).</p>
<p>A pratical application is about scientific publications. The amount of digital text data is growing exponentially and it is time consuming for researchers to find relevant information and the researched more connected to the same area of research. We can use the following variabels: </br>
1 - user: the name of researchers </br>
2 - topics: the specific area of research </br>
3 - cites: number of quotes received by an article </br>
4 - date: date of publication used as a cut-off to split the data between train and test set </br>
Having there variables we can implement a ANN to find attribute of the users finding researchers with similar influence on a specific topic based on a the number of quotes (collaborative filtering).
We can also try to use a more simple approach: <strong>content based filtering</strong>. </br></p>
<p><strong>Content based filtering applied to scientific publications</strong> </br>
The content based filtering recommend items (scientific articles) based on the attributes of those items themselves.
The figure below is an example of the <strong>cosine similarity</strong> to find similar articles.</p>
<center>
<p><img src="/img/cosinesim.png" style="width:80.0%" /></p>
</center>
<p>The article 1 (attentional bias in smokers) has a theta angle of 45 degree and this corrispond to a similarity of 0.7. This means that the article 1 is related to both the topic brain attention mechanisms and drug addiction. Bolow the formula to calculate the cosine similarity in amultidimentional space.</p>
<p><span class="math display">\[
\operatorname{cossim}(x, y)=\frac{\sum_{i} x_{i} y_{i}}{\sqrt{\sum_{i} x_{i}^{2}} \sqrt{\sum_{i} y_{i}^{2}}}
\]</span></p>
<p>The x and y in the formula above are topic1 and topic2 respectively. By taking the summation of each topic x and y and dividing by the square root of the summations squared, we end up with the cosine similarity score.
We can also take in consideration the <strong>date of publication</strong> of the articles. The idea is that how far apart would two movies have to be for their date of publication, signify that they are sunstantially different. A decade shoudl be a reasonable starting point (e.g. an article about brain activity in the 80s are different the same article in the 90s).
We can use the code below to scale the difference in dates from zero to one.</p>
<pre class="python"><code>def computeYearSimilarity(self, topic1, topic2, years):
       diff = abs(years[topic1] - years[topic2])
       sim = math.exp(-diff / 10.0)
       return sim
       </code></pre>
<p>From the code above we can see the <strong>exponential decay function</strong> is used. The similarity socre decays exponentially which is relly small after 10 years and almost nothing after 20 years as we can see from the figure below.</p>
<center>
<p><img src="/img/exponentialdecay.png" style="width:30.0%" /></p>
</center>
<p>In the real world we can use test many variatins of this function to see what really produces the best recommendations with real articles.
To predict a rating for a given researcher and for a given topic can be made using a <a href="https://www.andreaperlato.com/mlpost/estimate-the-sucess-of-a-new-product-with-logistic-regression/"><strong>k nearest neighbors</strong></a>. The idea is to measure the similarity score between the article and all other article rates (e.g. number of cites). In this case <strong>nearest neighbors</strong> are the articles with the highest content-based similarity scores, and we can use the top 10 nearest articles to recommend to the users.</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://www.rstudio.com/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-51254710-89', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

