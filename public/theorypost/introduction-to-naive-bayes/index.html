<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.6" />


<title>Introduction to Naive Bayes - Andrea Perlato</title>
<meta property="og:title" content="Introduction to Naive Bayes - Andrea Perlato">



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/graphpost/">Graph</a></li>
    
    <li><a href="/mlpost/">Machine Learning</a></li>
    
    <li><a href="/aipost/">Artificial Intelligence</a></li>
    
    <li><a href="/tspost/">Time Series</a></li>
    
    <li><a href="/theorypost/">Theory</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Introduction to Naive Bayes</h1>

    

    <div class="article-content">
      


<style>
body {
text-align: justify}
</style>
<p>It is a Probability Classifier. Naïve Bayes is the first algorithm that should be considered for solving <strong>Text Classification Problem</strong> which involves High Dimensional training Dataset. A few examples are: Sentiment Analysis and Classifying Topics on Social Media. </br>
It also refers to the Bayes’ Theorem also known as Bayes’ Law that give us a method to calculate the <strong>Conditional Probability</strong>: that is the probability of an event, based on previous knowledge available on the events.</p>
<p>Consider for example to have two features: <strong>Salary</strong> and <strong>Age</strong>. Some <strong>Walks</strong> to go at work and other <strong>Drive</strong> at work.</p>
<p><span class="math display">\[
P(W a l k s | X)=\frac{P(X | \text { Walks }) * P(\text { Walks })}{P(X)}
\]</span></p>
<p>The <strong>X</strong> represent the features (Salary or Age) of a specific person. </br></p>
<p><strong>What is the probability that the person goes to work on foot based on X (Salary and Age)?</strong>
P(Walks) = <strong>Prior probability</strong>, P(X) = <strong>Marginal likelihood</strong>, P(X|Walks) = <strong>Likelihood</strong>. The result of this calculation is P(Walks|X) = <strong>Posterior probability</strong>. Now, the same have to be made for Drive.</p>
<center>
<img src="/img/posteriorbayes.png" style="width:50.0%" />
</center>
<p>Finally, we have to compare P(Walks|X) vs. P(Drives|X), and from there we can decide in which class we have to put our new observatioin.</p>
<p><strong>Prior Probability</strong> </br>
In our example is the <strong>Probability that somebody Walks at work</strong> without knowing about hisAge or Salary. Looking at the figure below, we have to calculate the number of red observations and devide it by the overall number.</p>
<center>
<img src="/img/priorprobability.png" style="width:50.0%" />
</center>
<p><strong>Marginal Likelihood</strong> </br>
We select a circle around our point (person) that we have to estimate. Then, we calculate the probability of Similar Features (walks, drives) that this person has with the other observations (person). So, Marginal Likelihood says to us what is the likelihood of any new random variable that we have fully inside the circle that we defined.</p>
<center>
<img src="/img/marginallikelihood.png" style="width:50.0%" />
</center>
<p><strong>Likelihood</strong> </br>
It answer the following question: <strong>what is the probability of a randomly selected observations to be similar to the observations that we selected by the circle?</strong>
In our example, this means that we take into consideration only the red points (i.e. people that work at work). We are asking what is the likelihood that a randomly selected data point is someone that exhibit features similar to the people selected in the random circle.</p>
<center>
<img src="/img/likeliprob.png" style="width:50.0%" />
</center>
<p><strong>Naive Bayes in Machine Learning</strong> </br>
In a Machine Learning classification problem where there are multiple features and classes, the aim of the Naïve Bayes is to calculate the conditional probability of an object with the feature vector x1, x2, xn. So, it is able to calculate the probability of a particular class <strong>Ci</strong> given <strong>N</strong> number of features. </br>
Naive Bayes is an effective and commonly-used, machine learning classifier. It is a probabilistic classifier that makes classifications using the Maximum A Posteriori decision rule in a Bayesian setting. It can also be represented using a very simple Bayesian network. Naive Bayes classifiers have been especially popular for text classification, and are a traditional solution for problems such as <strong>Spam Detection</strong>. </br></p>
<p>An intuitive explanation for the <strong>Maximum A Posteriori Probability MAP</strong> is to think probabilities as degrees of belief. For example, how likely are we vote for a candidate depends on our prior belief. We can modify our stand based on the evidence. Our final decision, based on evidence, is the posterior belief, which is what happens after we sifted through the evidence. <strong>MPA</strong> is simply the maximum posterior belief: after going through all the debates, what is your most likely decision?</p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://www.rstudio.com/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-51254710-89', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

