---
title: Text Mining Clustering Tweets
author: andrea perlato
date: '2019-08-02'
slug: text-mining-clustering-tweets
categories:
  - text mining
tags:
  - clustering
  - hierarchical clustering
---



<style>
body {
text-align: justify}
</style>
<p>We can use Unsupervised Classification (clustering) to learn more about text that we have to analyze. More specifically, we use <a href="https://www.andreaperlato.com/theorypost/introduction-to-k-means-and-hierarchical-clustering/"><strong>Hierarchical clustering</strong></a> to cluster our text into groups that are the propensity to occur together. In this example, text are some tweet about <a href="https://en.wikipedia.org/wiki/2017_Catalan_independence_referendum"><strong>Catalan Independence Referendum</strong></a>.</p>
<p>First step is to convert our tweets into a corpus, remove punctuation, transform everything into lowercase, remove numbers, and stop words. Then, we have to stamming the document, and finally we have a corpus of terms. with out sparse terms.</p>
<pre class="r"><code>library(tm)

corpus &lt;- Corpus(VectorSource(d$text))
corpus &lt;- tm_map(corpus, removePunctuation)
corpus &lt;- tm_map(corpus, content_transformer(tolower))
corpus &lt;- tm_map(corpus, removeNumbers)
corpus &lt;- tm_map(corpus, stripWhitespace)
corpus &lt;- tm_map(corpus, removeWords, stopwords(&#39;english&#39;))
corpus &lt;- tm_map(corpus, stemDocument)

# Create term document matrix
tdm &lt;- TermDocumentMatrix(corpus,control = list(minWordLength=c(1,Inf)))

t &lt;- removeSparseTerms(tdm, sparse=0.90) # remove words not appear 90% of the time</code></pre>
<p>Next step is to create a matrix of word frequency, and we can plot the words that occur more than 200 times, as shown in the graph below.</p>
<pre class="r"><code>m &lt;- as.matrix(t) # create a matrix of word frequencies

# Plot frequent terms
freq &lt;- rowSums(m)
freq &lt;- subset(freq, freq&gt;=200)

barplot(freq, las=2, col = rainbow(25))</code></pre>
<p><img src="/MLPost/2019-08-02-text-mining-clustering-tweets_files/figure-html/unnamed-chunk-3-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obviously, <strong>catalonia</strong> is the most common term, but we have also other interesting high frequency words, such as <strong>solidar</strong>.
Now, we can use Hierarchical clustering of the words using Dendrogram.</p>
<pre class="r"><code># Hierarchical word tweet clustering using dendrogram 

distance &lt;- dist(scale(m)) # distance between different terms

# print(distance, digits = 2)

hc &lt;- hclust(distance, method = &quot;ward.D&quot;) # use ward.D for heirarchial clustering
# plot(hc, hang=-1)
# rect.hclust(hc, k=12)

library(dendextend) # color dendrogram

dend &lt;- hc
dend &lt;- color_branches(dend, k = 3)
dend &lt;- color_labels(dend, k = 3)

# Represent the different  clusters with different colors
plot(dend, main = &#39;Cluster Dendrogram&#39;, ylab = &#39;Height&#39;)</code></pre>
<p><img src="/MLPost/2019-08-02-text-mining-clustering-tweets_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the graph above, we can see that to different cluster has been assigned a different color.
To learn more about Hierarchical clustering and Dendrogram, <a href="https://www.andreaperlato.com/theorypost/introduction-to-k-means-and-hierarchical-clustering/"><strong>look at this post</strong></a>.</p>
