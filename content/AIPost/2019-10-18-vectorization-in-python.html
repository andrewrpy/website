---
title: Vectorization in Python
author: andrea perlato
date: '2019-10-18'
slug: vectorization-in-python
categories:
  - artificial intelligence
tags:
  - vectorization
---



<style>
body {
text-align: justify}
</style>
<p>In deep learing we often deal with large data sets. It is important to run the code quickly because otherwise the code might take a long time to get the results.
That is why perform vectorization has become a key skill.</p>
<p>For example in <strong>logistic regression</strong> we need to to compute <strong>w transpose x</strong> in a non-vectorized implementation we can use the following code:</p>
<p><span class="math display">\[
\begin{array}{l}{\quad z=\underbrace{\omega^{\top} x}_{}+b} \\ {\text { Non-vectorized }} \\ {z=0} \\ {\text { for } i \text { in } \operatorname{range}(n-x) \text { : }} \\ {z+=\omega Ti] * x \ \text { Ti } } \\ {z+=b}\end{array}
\]</span>
In contrast, a vectorized implementation can me made using <strong>numpy</strong> in python. This implementation is much faster to compute.</p>
<pre class="python"><code>import numpy as np
import time

# Vectorized implementation
a = np.random.rand(1000000) # million dimentional array
b = np.random.rand(1000000)

tic = time.time()
c = np.dot(a,b) # both a and b are arrays
toc = time.time()

print(&quot;Vectorized version:&quot; + str(1000*(toc-tic)) +&quot;ms&quot;)


# Non-vectorized implementation</code></pre>
<pre><code>## Vectorized version:15.591144561767578ms</code></pre>
<pre class="python"><code>c = 0
tic = time.time()
for i in range(1000000):
    c += a[i]*b[i]
toc = time.time()

print(&quot;For loop:&quot; + str(1000*(toc-tic)) +&quot;ms&quot;)
    
</code></pre>
<pre><code>## For loop:422.9731559753418ms</code></pre>
<p>As we can see from the code above, the Non-vectorized version (For loop) is much longer (462.32 ms) than the Vectorized version (8.13 ms).
This means that when we implement a deep learning algorithm weget result back much faster if we vectorized our code.
There is also another scalable implementation of deep learning using <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit"><strong>GPU</strong></a> a <strong>Graphics Processing Unit</strong>, and both CPU and GPU have parallelization instructions called <a href="https://en.wikipedia.org/wiki/SIMD"><strong>SIMD</strong></a> that stands for <strong>Single Instruction Multiple Data</strong>. That means that if we use a built-in function such as the <strong>np.dot()</strong> the SIMD enables Python to take much better advantages of parallelism to do our computations much faster. This is true both on CPUs and GPUs.</p>
